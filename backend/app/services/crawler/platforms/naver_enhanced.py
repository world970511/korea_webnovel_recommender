"""
Enhanced Naver Series Crawler with Detail Page Extraction

ìƒì„¸ í˜ì´ì§€ ë°©ë¬¸ì„ í†µí•œ ì™„ì „í•œ ì •ë³´ ìˆ˜ì§‘
"""

import asyncio
from typing import List, Dict, Optional
from backend.app.services.crawler.base import BaseCrawler
from backend.app.config import settings


class NaverSeriesCrawlerEnhanced(BaseCrawler):
    """
    í–¥ìƒëœ ë„¤ì´ë²„ ì‹œë¦¬ì¦ˆ í¬ë¡¤ëŸ¬.

    ëª©ë¡ í˜ì´ì§€ì˜ ê°„ë‹¨í•œ ì •ë³´ë§Œ ìˆ˜ì§‘í•˜ëŠ” ëŒ€ì‹ ,
    ê° ì†Œì„¤ì˜ ìƒì„¸ í˜ì´ì§€ë¥¼ ë°©ë¬¸í•˜ì—¬ ì™„ì „í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    """

    BASE_URL = "https://series.naver.com/novel"
    LOGIN_URL = "https://nid.naver.com/nidlogin.login"

    GENRE_MAP = {
        "íŒíƒ€ì§€": "fantasy",
        "í˜„ëŒ€íŒíƒ€ì§€": "modern_fantasy",
        "ë¡œë§¨ìŠ¤": "romance",
        "ë¡œë§¨ìŠ¤íŒíƒ€ì§€": "romance_fantasy",
        "ë¬´í˜‘": "martial_arts",
        "BL": "bl",
        "ë¯¸ìŠ¤í„°ë¦¬": "mystery",
        "ë“œë¼ë§ˆ": "drama",
    }

    def __init__(self, skyvern_client):
        """Initialize enhanced Naver Series crawler."""
        super().__init__(skyvern_client, "naver_series")
        self.is_logged_in = False

    async def crawl_genre_with_details(
        self,
        genre: str,
        limit: int = 20,
        include_adult: bool = False
    ) -> List[Dict]:
        """
        ìƒì„¸ í˜ì´ì§€ ë°©ë¬¸ì„ í¬í•¨í•œ í¬ë¡¤ë§.

        Args:
            genre: Genre name in Korean
            limit: Maximum number of novels to collect
            include_adult: Whether to include adult content

        Returns:
            List of novel dictionaries with complete information
        """
        if include_adult and not self.is_logged_in:
            if settings.naver_username and settings.naver_password:
                await self.login(settings.naver_username, settings.naver_password)

        genre_code = self.GENRE_MAP.get(genre, "fantasy")
        genre_url = f"{self.BASE_URL}/genre/{genre_code}"

        self.logger.info(f"Starting enhanced crawl of {genre} from {genre_url}")

        # í™•ì¥ëœ ìŠ¤í‚¤ë§ˆ - ìƒì„¸ í˜ì´ì§€ì—ì„œ ìˆ˜ì§‘í•  ì •ë³´ í¬í•¨
        extraction_schema = {
            "title": "ì†Œì„¤ ì œëª©",
            "author": "ì‘ê°€ ì´ë¦„",
            "description": "ì†Œì„¤ ìƒì„¸ ì¤„ê±°ë¦¬ (ê¸´ ë²„ì „)",
            "short_description": "ì§§ì€ ì†Œê°œê¸€",
            "url": "ì†Œì„¤ ìƒì„¸ í˜ì´ì§€ URL",
            "keywords": "ì¥ë¥´, íƒœê·¸, í‚¤ì›Œë“œ (ì‰¼í‘œ êµ¬ë¶„)",
            "status": "ì—°ì¬ ìƒíƒœ (ì—°ì¬ì¤‘/ì™„ê²°)",
            "total_episodes": "ì „ì²´ ì—í”¼ì†Œë“œ ìˆ˜",
            "rating": "ë³„ì  ë˜ëŠ” í‰ì ",
            "views": "ì¡°íšŒìˆ˜",
            "likes": "ì¢‹ì•„ìš” ìˆ˜",
        }

        # ğŸ”‘ í•µì‹¬: ìƒì„¸ í˜ì´ì§€ ë°©ë¬¸ì„ ëª…ì‹œí•œ í”„ë¡¬í”„íŠ¸
        prompt = f"""
        ë„¤ì´ë²„ ì‹œë¦¬ì¦ˆ {genre} ì¥ë¥´ì—ì„œ ì†Œì„¤ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”.

        â­ ì¤‘ìš”: ê° ì†Œì„¤ë§ˆë‹¤ ìƒì„¸ í˜ì´ì§€ì— ë“¤ì–´ê°€ì„œ ì™„ì „í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”!

        ë‹¨ê³„ë³„ ì‘ì—…:

        1. ëª©ë¡ í˜ì´ì§€ì—ì„œ ì†Œì„¤ ì¹´ë“œ í™•ì¸
           - ì œëª©ê³¼ ì‘ê°€ëª… í™•ì¸
           - ìƒì„¸ í˜ì´ì§€ ë§í¬ ì°¾ê¸°

        2. ê° ì†Œì„¤ì˜ ìƒì„¸ í˜ì´ì§€ë¡œ ì´ë™ (ë§í¬ í´ë¦­)
           - ì™„ì „í•œ ì¤„ê±°ë¦¬/ì‹œë†‰ì‹œìŠ¤ ìˆ˜ì§‘
           - ì—°ì¬ ìƒíƒœ (ì—°ì¬ì¤‘/ì™„ê²°) í™•ì¸
           - ì „ì²´ ì—í”¼ì†Œë“œ ìˆ˜ í™•ì¸
           - íƒœê·¸ì™€ í‚¤ì›Œë“œ ëª¨ë‘ ìˆ˜ì§‘
           - í‰ì , ì¡°íšŒìˆ˜, ì¢‹ì•„ìš” ìˆ˜ í™•ì¸

        3. ëª©ë¡ í˜ì´ì§€ë¡œ ëŒì•„ê°€ê¸° (ë’¤ë¡œê°€ê¸°)

        4. ë‹¤ìŒ ì†Œì„¤ë¡œ ì´ë™í•˜ì—¬ 2-3 ë°˜ë³µ

        5. {limit}ê°œ ìˆ˜ì§‘í•  ë•Œê¹Œì§€ ê³„ì†
           - í•„ìš”í•˜ë©´ "ë‹¤ìŒ í˜ì´ì§€" í´ë¦­

        ìˆ˜ì§‘í•  ì •ë³´:
        - ì œëª©: ì •í™•í•œ ì†Œì„¤ ì œëª©
        - ì‘ê°€: ì‘ê°€ëª… ë˜ëŠ” í•„ëª…
        - ìƒì„¸ ì¤„ê±°ë¦¬: ìƒì„¸ í˜ì´ì§€ì˜ ì „ì²´ ì¤„ê±°ë¦¬ (ëª©ë¡ì˜ ì§§ì€ ì†Œê°œê¸€ì´ ì•„ë‹˜!)
        - ì§§ì€ ì†Œê°œ: ëª©ë¡ì— í‘œì‹œëœ ì§§ì€ ì„¤ëª…
        - URL: ìƒì„¸ í˜ì´ì§€ ì „ì²´ ì£¼ì†Œ
        - íƒœê·¸/í‚¤ì›Œë“œ: #ë¡œ ì‹œì‘í•˜ëŠ” íƒœê·¸, ì¥ë¥´ ë¶„ë¥˜ ë“± ëª¨ë‘
        - ì—°ì¬ ìƒíƒœ: "ì—°ì¬ì¤‘" ë˜ëŠ” "ì™„ê²°"
        - ì—í”¼ì†Œë“œ ìˆ˜: ì´ ëª‡ í™”ì¸ì§€
        - í‰ì : ë³„ì  (ì˜ˆ: 9.8ì )
        - ì¡°íšŒìˆ˜: ì „ì²´ ì¡°íšŒìˆ˜
        - ì¢‹ì•„ìš”: ì¢‹ì•„ìš” ë˜ëŠ” ì¶”ì²œ ìˆ˜

        ì£¼ì˜ì‚¬í•­:
        - ë°˜ë“œì‹œ ìƒì„¸ í˜ì´ì§€ì— ë“¤ì–´ê°€ì„œ ì •ë³´ ìˆ˜ì§‘!
        - ëª©ë¡ì˜ ì§§ì€ ì •ë³´ë§Œìœ¼ë¡œ ë„˜ì–´ê°€ì§€ ë§ ê²ƒ
        - ì •ë³´ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ ì €ì¥
        - ê´‘ê³ ë‚˜ ë°°ë„ˆëŠ” ë¬´ì‹œ
        - ì¤‘ë³µ ì œëª© ì œì™¸
        {'- 19ì„¸ ì´ìƒ ì½˜í…ì¸  í¬í•¨' if include_adult else '- 19ì„¸ ì´ìƒ ì½˜í…ì¸  ì œì™¸'}
        """

        try:
            # Skyvern ì‹¤í–‰ - max_stepsë¥¼ ëŠ˜ë ¤ì„œ ìƒì„¸ í˜ì´ì§€ ë°©ë¬¸ ì‹œê°„ í™•ë³´
            result = await self.client.run_task(
                url=genre_url,
                prompt=prompt,
                data_extraction_goal="\n".join([
                    f"{k}: {v}" for k, v in extraction_schema.items()
                ]),
                max_steps=limit * 3  # ê° ì†Œì„¤ë‹¹ 3 ìŠ¤í… (ëª©ë¡â†’ìƒì„¸â†’ë³µê·€)
            )

            # ê²°ê³¼ ì²˜ë¦¬
            raw_novels = result.get("extracted_data", [])

            novels = []
            for raw_novel in raw_novels[:limit]:
                try:
                    normalized = self.normalize_novel_data_enhanced(raw_novel)
                    if genre not in normalized["keywords"]:
                        normalized["keywords"].append(genre)
                    novels.append(normalized)
                except Exception as e:
                    self.logger.warning(f"Failed to normalize novel: {str(e)}")
                    continue

            self.log_crawl_summary(novels)
            return novels

        except Exception as e:
            self.logger.error(f"Failed to crawl {genre}: {str(e)}")
            return []

    def normalize_novel_data_enhanced(self, raw_data: Dict) -> Dict:
        """
        í™•ì¥ëœ í•„ë“œë¥¼ í¬í•¨í•œ ë°ì´í„° ì •ê·œí™”.

        Args:
            raw_data: Raw data from Skyvern with enhanced fields

        Returns:
            Normalized novel dictionary with additional metadata
        """
        # ê¸°ë³¸ í•„ë“œ
        base_novel = {
            "title": raw_data.get("title", "").strip(),
            "author": raw_data.get("author", "").strip(),
            "description": raw_data.get("description", "").strip(),
            "platform": self.platform_name,
            "url": raw_data.get("url", "").strip(),
            "keywords": self._extract_keywords(raw_data),
        }

        # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
        metadata = {
            "short_description": raw_data.get("short_description", "").strip(),
            "status": raw_data.get("status", "").strip(),
            "total_episodes": self._parse_number(raw_data.get("total_episodes")),
            "rating": self._parse_float(raw_data.get("rating")),
            "views": self._parse_number(raw_data.get("views")),
            "likes": self._parse_number(raw_data.get("likes")),
        }

        # ì—°ì¬ ìƒíƒœë¥¼ í‚¤ì›Œë“œì— ì¶”ê°€
        if metadata["status"]:
            base_novel["keywords"].append(metadata["status"])

        # ë©”íƒ€ë°ì´í„°ë¥¼ ì„¤ëª…ì— ì¶”ê°€ (ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ)
        if metadata["status"] or metadata["total_episodes"]:
            extra_info = []
            if metadata["status"]:
                extra_info.append(f"[{metadata['status']}]")
            if metadata["total_episodes"]:
                extra_info.append(f"[ì´ {metadata['total_episodes']}í™”]")

            base_novel["description"] += " " + " ".join(extra_info)

        return base_novel

    def _parse_number(self, value) -> Optional[int]:
        """Extract number from string."""
        if not value:
            return None

        import re
        # "1,234íšŒ" â†’ 1234
        numbers = re.findall(r'\d+', str(value).replace(",", ""))
        return int(numbers[0]) if numbers else None

    def _parse_float(self, value) -> Optional[float]:
        """Extract float from string."""
        if not value:
            return None

        import re
        # "9.8ì " â†’ 9.8
        match = re.search(r'(\d+\.?\d*)', str(value))
        return float(match.group(1)) if match else None

    async def crawl_genre(
        self,
        genre: str,
        limit: int = 20,
        include_adult: bool = False
    ) -> List[Dict]:
        """
        ê¸°ë³¸ í¬ë¡¤ë§ ë©”ì„œë“œ - ìƒì„¸ í˜ì´ì§€ ë°©ë¬¸ ë²„ì „ìœ¼ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸.
        """
        return await self.crawl_genre_with_details(genre, limit, include_adult)

    async def login(self, username: str, password: str) -> bool:
        """Login to Naver."""
        try:
            self.logger.info(f"Attempting Naver login for {username}")

            success = await self.client.login_to_site(
                url=self.LOGIN_URL,
                username=username,
                password=password,
                username_field_desc="ì•„ì´ë”” ì…ë ¥ë€",
                password_field_desc="ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ë€",
                login_button_desc="ë¡œê·¸ì¸ ë²„íŠ¼"
            )

            self.is_logged_in = success
            return success

        except Exception as e:
            self.logger.error(f"Login failed: {str(e)}")
            return False
